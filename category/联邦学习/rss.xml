<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>hc‘s blog • Posts by &#34;联邦学习&#34; category</title>
        <link>http://example.com</link>
        <description></description>
        <language>en</language>
        <pubDate>Sun, 07 Mar 2021 16:06:41 +0800</pubDate>
        <lastBuildDate>Sun, 07 Mar 2021 16:06:41 +0800</lastBuildDate>
        <item>
            <guid isPermalink="true">http://example.com/2021/03/07/%E7%BA%B5%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/</guid>
            <title>纵向联邦学习</title>
            <link>http://example.com/2021/03/07/%E7%BA%B5%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/</link>
            <pubDate>Sun, 07 Mar 2021 16:06:41 +0800</pubDate>
            <description><![CDATA[ &lt;h4 id=&#34;纵向联邦学习的定义与举例&#34;&gt;&lt;a href=&#34;#纵向联邦学习的定义与举例&#34; class=&#34;headerlink&#34; title=&#34;纵向联邦学习的定义与举例&#34;&gt;&lt;/a&gt;纵向联邦学习的定义与举例&lt;/h4&gt;&lt;p&gt;我们把在数据集上具有相同的样本空间、不同的特征空间的参与方所组成的联邦学习归类为纵向联邦学习（VFL）。&lt;/p&gt;
&lt;p&gt;假如有一位用户在一家银行中有一些能够反映出该用户的经济收入、消费习惯和信用评级的数据记录。同时在一家电商平台中记录着这位用户所浏览和购买的商品的历史信息。尽管这两家公司拥有用户数据的特征空间完全不同，他们彼此间却有着紧密的联系。例如，用户的购买历史可能在某种程度上决定了该用户的信用评级。&lt;/p&gt;
&lt;p&gt;出于不同的商业目的，不同的组织拥有的数据通常具有不同的特征空间，但这些组织可能共享一个巨大的用户群体。通过使用VFL，我们可以利用分布于这些组织的异构数据，搭建更好的机器学习模型，并且不需要交换和泄露隐私数据。&lt;/p&gt;
&lt;h4 id=&#34;纵向联邦学习的架构&#34;&gt;&lt;a href=&#34;#纵向联邦学习的架构&#34; class=&#34;headerlink&#34; title=&#34;纵向联邦学习的架构&#34;&gt;&lt;/a&gt;纵向联邦学习的架构&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&#34;https://i.imgtg.com/2023/03/09/Y9OHB.png&#34; alt=&#34;image-20210309235515471&#34;&gt;&lt;/p&gt;
&lt;p&gt;举个例子。假设两家公司A和B想要协同地训练一个机器学习模型。每一家公司拥有各自的数据，此外B还拥有进行模型预测任务所需的标注数据。由于用户隐私和数据安全的原因，A方和B 方不能直接交换数据。为了保证训练过程中的数据保密性，加入了一个第三方协调者C。在这里，我们假设C方是诚实且不与A方和B方共谋，但A方和B方都是诚实但好奇的。被信任的第三方是一个合理的假设，因为C方的角色可以有权威机构（如政府）扮演或安全计算节点代替。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一部分：加密实体对齐&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于A方和B方公司的用户群体不同，系统使用一种基于加密的用户ID对齐技术，来确保A方和B方不需要暴露各自的原始数据便可以对齐共同用户。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第二部分：加密模型训练&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在确定共有实体后，各方可以使用这些共有实体的数据来协同地训练一个机器学习模型。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;协调者C创建密钥对，并将公共密钥发送给A方和B方。&lt;/li&gt;
&lt;li&gt;A方和B方对中间结果进行加密和交换。中间结果用来帮助计算梯度和损失值。&lt;/li&gt;
&lt;li&gt;A方和B方计算加密梯度并分别加入附加掩码。B方还会计算加密损失。A方和B方将加密的结果发送给C方。&lt;/li&gt;
&lt;li&gt;C方对梯度和损失信息进行解密，并将结果发送回A方和B方。A方和B方解除梯度信息上的掩码，并根据这些梯度信息来更新模型参数&lt;/li&gt;
&lt;/ol&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">http://example.com/2021/03/06/3.6%E4%B8%BA%E4%BA%86%E8%82%9D%E5%91%A8%E6%8A%A5%E7%9A%84%E5%AD%A6%E4%B9%A0/</guid>
            <title>横向联邦学习</title>
            <link>http://example.com/2021/03/06/3.6%E4%B8%BA%E4%BA%86%E8%82%9D%E5%91%A8%E6%8A%A5%E7%9A%84%E5%AD%A6%E4%B9%A0/</link>
            <pubDate>Sat, 06 Mar 2021 13:47:32 +0800</pubDate>
            <description><![CDATA[ &lt;h4 id=&#34;定义：&#34;&gt;&lt;a href=&#34;#定义：&#34; class=&#34;headerlink&#34; title=&#34;定义：&#34;&gt;&lt;/a&gt;定义：&lt;/h4&gt;&lt;p&gt;横向联邦学习也称为按样本划分的联邦学习，可以应用于联邦学习的各个参与方的数据集有相同的特征空间和不同的样本空间的场景，类似于再表格视图中对数据进行水平划分的情况。&lt;/p&gt;
&lt;p&gt;举例来说，两个地区的城市商业银行可能在各自的区域拥有非常不同的客户群体，所以他们的客户交集非常小，他们的数据集有不同的样本id。然而，他们的业务非常相似，因此他们的数据集的特征空间是相同的。这两家可以联合起来进行横向联邦学习以构建更好的风控模型。&lt;/p&gt;
&lt;p&gt;关于横向联邦学习系统的安全性的定义，我们通常假设一个横向联邦学习系统的参与方都是诚实的，需要防范的对象是一个诚实但好奇的聚合服务器。即通常假设只有服务器才能使得数据参与方的隐私安全受到威胁。&lt;/p&gt;
&lt;p&gt;以下是一些已提出的学习方法：&lt;/p&gt;
&lt;p&gt;参与方独立地训练模型并只分享参数更新的子集，这是横向联邦学习的一种特殊形式。&lt;/p&gt;
&lt;p&gt;在联邦学习框架下对用户模型更新或者对梯度信息进行安全聚合。&lt;/p&gt;
&lt;p&gt;适用于模型参数聚合的加法同态加密，能够防御联邦学习系统里的中央服务器窃取模型信息或者数据隐私。&lt;/p&gt;
&lt;p&gt;还有一种叫做深度梯度压缩的压缩方法，能够大幅度降低在大规模分布式训练中需要的通信宽带。&lt;/p&gt;
&lt;p&gt;甚至，另一种考虑了恶意用户的安全模型也被提出，这带来了联邦学习新的安全挑战。当联邦学习训练结束时，聚合模型和整个模型的参数都会暴露给所有的参与方。&lt;/p&gt;
&lt;h4 id=&#34;横向联邦学习架构&#34;&gt;&lt;a href=&#34;#横向联邦学习架构&#34; class=&#34;headerlink&#34; title=&#34;横向联邦学习架构&#34;&gt;&lt;/a&gt;横向联邦学习架构&lt;/h4&gt;&lt;h5 id=&#34;客户-服务器构架&#34;&gt;&lt;a href=&#34;#客户-服务器构架&#34; class=&#34;headerlink&#34; title=&#34;客户-服务器构架&#34;&gt;&lt;/a&gt;客户-服务器构架&lt;/h5&gt;&lt;p&gt;由于资料的缺失，这一部分先不讨论。&lt;/p&gt;
&lt;h5 id=&#34;对等网络架构&#34;&gt;&lt;a href=&#34;#对等网络架构&#34; class=&#34;headerlink&#34; title=&#34;对等网络架构&#34;&gt;&lt;/a&gt;对等网络架构&lt;/h5&gt;&lt;p&gt;在该架构下，不存在中央服务器或者协调方。在这种架构中，横向联邦学习系统的K个参与方或者分布式训练方。每一个训练方负责只使用本地数据来训练同一个机器学习模型，此外，训练方们使用安全链路在相互之间传递模型参数信息。为了保证任意两方之间的通信安全，需要使用例如基于公共密钥的加密方法等安全措施。&lt;/p&gt;
&lt;p&gt;由于对等网络架构中不存在中央服务器，训练方必须提前商定发送和接受模型参数信息的顺序，主要有两个方法可以达到这个目的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;循环传输&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;训练方被组织成一条链。第一个训练方将当前的模型参数发送给它的下一个训练方。该训练方接受来自上游的模型参数后，将使用来自本地数据集的小批量数据更新收到的模型参数。之后，它将更新后的模型参数传输给下一个训练方。这一过程将被持续重复，直到模型参数收敛或达到允许的组大训练时间。&lt;/p&gt;
&lt;p&gt;  2.随机传输&lt;/p&gt;
&lt;p&gt;第k个训练方选取i，并将模型参数发送给训练方i。当第i个训练方收到来自第i个训练方的模型参数后，它将使用来自本地数据集的数据的&lt;strong&gt;mini-batch&lt;/strong&gt;更新收到的模型参数。之后，第i个训练方选一个j，并将自己的模型参数发送给训练方j。这一过程将会重复，直到K个训练方同意模型参数收敛或达到允许的最大训练时间。这种方法叫做Gossip学习。&lt;/p&gt;
&lt;p&gt;与客户-服务器相比，对等网络架构的一个明显优点便是除去了中央服务器，而这类服务器在一些实际应用中可能难以获得或建立。但这一特性，也可能带来一些坏处，例如在循环传输模式中，由于没有中央服务器，权重参数并不分批量更新而是连续更新,这将导致训练模型耗费更多的时间。&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
